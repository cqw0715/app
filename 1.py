import streamlit as st
import torch
import numpy as np
import pandas as pd
import os
import pickle
from io import StringIO
from torch.utils.data import DataLoader, TensorDataset
import esm
import time
from typing import List, Tuple, Optional, Union
from tqdm import tqdm

# ==========================================
# å¼ºåˆ¶ä½¿ç”¨ CPUï¼ˆæ—  GPU ç¯å¢ƒï¼‰
# ==========================================
device = torch.device('cpu')
st.info("â„¹ï¸ å½“å‰è¿è¡Œåœ¨ CPU æ¨¡å¼ï¼ˆæ—  GPUï¼‰")

# ==========================================
# å®‰å…¨çš„ Mamba å®ç°ï¼šå§‹ç»ˆä½¿ç”¨æ›¿ä»£ç‰ˆï¼ˆå›  mamba_ssm ä¸æ”¯æŒ CPUï¼‰
# ==========================================
class Mamba(nn.Module):
    """çº¯ PyTorch å®ç°çš„ Mamba æ›¿ä»£æ¨¡å—ï¼ˆä»…ç”¨äº CPU å…¼å®¹ï¼‰"""
    def __init__(self, d_model, d_state=16, d_conv=4, expand=2):
        super().__init__()
        self.d_model = d_model
        self.norm = nn.LayerNorm(d_model)

    def forward(self, x):
        return self.norm(x)


# ==========================================
# æ¨¡å‹æ¶æ„å®šä¹‰ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
# ==========================================
import torch.nn as nn
import torch.nn.functional as F


class CNNBranch(nn.Module):
    def __init__(self, input_dim=480, num_classes=2):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.BatchNorm1d(256),
            nn.Unflatten(1, (1, 256)),
            nn.Conv1d(1, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Conv1d(64, 128, kernel_size=3, padding=1),
            nn.Conv1d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Conv1d(256, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.AdaptiveMaxPool1d(1)
        )
        self.classifier = nn.Linear(128, num_classes)

    def forward(self, x):
        feat = self.net(x).flatten(1)
        return self.classifier(feat)


class TransformerBranch(nn.Module):
    def __init__(self, input_dim=480, d_model=256, nhead=8, num_classes=2):
        super().__init__()
        self.embedding = nn.Linear(input_dim, d_model)
        layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True, dropout=0.2)
        self.transformer = nn.TransformerEncoder(layer, num_layers=4)
        self.classifier = nn.Linear(d_model, num_classes)

    def forward(self, x):
        x = self.embedding(x).unsqueeze(1)
        x = self.transformer(x).squeeze(1)
        return self.classifier(x)


class MambaBranch(nn.Module):
    def __init__(self, input_dim, num_classes):
        super().__init__()
        self.preprocess = nn.Linear(input_dim, 256)
        self.mamba_blocks = nn.ModuleList([
            Mamba(d_model=256, d_state=16, d_conv=4, expand=2) for _ in range(5)
        ])
        self.norm = nn.LayerNorm(256)
        self.classifier = nn.Linear(256, num_classes)

    def forward(self, x):
        x = self.preprocess(x).unsqueeze(1)
        for block in self.mamba_blocks:
            x = x + block(x)
        x = self.norm(x).squeeze(1)
        return self.classifier(x)


class MutualLearningModel(nn.Module):
    def __init__(self, input_dim=480, num_classes=2, embed_dim=128):
        super().__init__()
        self.cnn = CNNBranch(input_dim, num_classes)
        self.trans = TransformerBranch(input_dim, num_classes=num_classes)
        self.mamba = MambaBranch(input_dim, num_classes)
        self.logits_norm = nn.LayerNorm(num_classes)
        self.feature_proj = nn.Sequential(
            nn.Linear(num_classes, embed_dim),
            nn.LayerNorm(embed_dim),
            nn.GELU()
        )
        self.attn1 = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=8, dropout=0.2, batch_first=True)
        self.attn_norm1 = nn.LayerNorm(embed_dim)
        self.ffn1 = nn.Sequential(
            nn.Linear(embed_dim, embed_dim * 4),
            nn.GELU(),
            nn.Dropout(0.2),
            nn.Linear(embed_dim * 4, embed_dim)
        )
        self.ffn_norm1 = nn.LayerNorm(embed_dim)
        self.attn2 = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=8, dropout=0.2, batch_first=True)
        self.attn_norm2 = nn.LayerNorm(embed_dim)
        self.ffn2 = nn.Sequential(
            nn.Linear(embed_dim, embed_dim * 4),
            nn.GELU(),
            nn.Dropout(0.2),
            nn.Linear(embed_dim * 4, embed_dim)
        )
        self.ffn_norm2 = nn.LayerNorm(embed_dim)
        total_gate_dim = embed_dim * 3 + num_classes * 3
        self.gate = nn.Sequential(
            nn.Linear(total_gate_dim, 256),
            nn.LayerNorm(256),
            nn.GELU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.LayerNorm(128),
            nn.GELU(),
            nn.Dropout(0.2),
            nn.Linear(128, 3)
        )
        self.log_temp = nn.Parameter(torch.tensor(np.log(0.8 + 1e-6)))
        self.refine = nn.Sequential(
            nn.Linear(num_classes, num_classes),
            nn.LayerNorm(num_classes),
            nn.GELU(),
            nn.Dropout(0.1)
        )

    def forward(self, x):
        o1, o2, o3 = self.cnn(x), self.trans(x), self.mamba(x)
        branches = torch.stack([o1, o2, o3], dim=1)
        branches_norm = self.logits_norm(branches)
        x_proj = self.feature_proj(branches_norm)
        attn_out, _ = self.attn1(x_proj, x_proj, x_proj)
        x = self.attn_norm1(x_proj + attn_out)
        x = self.ffn_norm1(x + self.ffn1(x))
        attn_out, _ = self.attn2(x, x, x)
        x = self.attn_norm2(x + attn_out)
        x = self.ffn_norm2(x + self.ffn2(x))
        raw_logits = branches.flatten(1)
        fused_proj = x.flatten(1)
        combined_feat = torch.cat([fused_proj, raw_logits], dim=1)
        gate_scores = self.gate(combined_feat)
        temp = F.softplus(self.log_temp) + 1e-4
        weights = F.softmax(gate_scores / temp, dim=1).unsqueeze(-1)
        o_fused = (branches * weights).sum(dim=1)
        o_fused = o_fused + self.refine(o_fused)
        return o1, o2, o3, o_fused


# ==========================================
# ç‰¹å¾æå–ç±»ï¼ˆCPU-onlyï¼Œç§»é™¤ CUDA ç›¸å…³ï¼‰
# ==========================================
class ESMFeatureExtractor:
    def __init__(self):
        self.model = None
        self.batch_converter = None
        self._initialize_models()

    def _initialize_models(self):
        print("ğŸ–¥ï¸ åŠ è½½ ESM-2 35M æ¨¡å‹ï¼ˆCPU æ¨¡å¼ï¼‰...")
        try:
            self.model, alphabet = esm.pretrained.esm2_t12_35M_UR50D()  # æ­£ç¡®æ¨¡å‹å
            self.model = self.model.to(device)
            self.model.eval()
            self.batch_converter = alphabet.get_batch_converter()
            print("âœ… ESM æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def _extract_batch_features(self, batch_data):
        _, _, batch_tokens = self.batch_converter(batch_data)
        batch_tokens = batch_tokens.to(device)
        with torch.no_grad():
            results = self.model(batch_tokens, repr_layers=[12], return_contacts=False)  # ç¬¬12å±‚
            token_representations = results["representations"][12]
        seq_lengths = (batch_tokens != self.model.alphabet.padding_idx).sum(1)
        batch_features = [
            token_representations[i, :seq_lengths[i]].mean(0).cpu().numpy()
            for i in range(token_representations.size(0))
        ]
        return batch_features

    def extract_features(self, sequences, cache_path=None, batch_size=1):
        if cache_path and os.path.exists(cache_path):
            print(f"ğŸ“‚ ä»ç¼“å­˜åŠ è½½ç‰¹å¾: {cache_path}")
            with open(cache_path, 'rb') as f:
                return pickle.load(f)

        features = []
        for i in range(0, len(sequences), batch_size):
            batch = sequences[i:i + batch_size]
            batch_data = [(str(idx), seq) for idx, seq in enumerate(batch)]
            features.extend(self._extract_batch_features(batch_data))
            if (i // batch_size) % 10 == 0:
                print(f"ğŸ“Š è¿›åº¦: {min(i + batch_size, len(sequences))}/{len(sequences)}")

        features_array = np.array(features)
        if cache_path:
            with open(cache_path, 'wb') as f:
                pickle.dump(features_array, f)
        return features_array


# ==========================================
# ç¼“å­˜å‡½æ•°
# ==========================================
@st.cache_resource
def get_feature_extractor():
    return ESMFeatureExtractor()


@st.cache_resource
def load_model_and_scaler():
    model_path = "best_mutual_learning_model.pth"
    if not os.path.exists(model_path):
        st.error(f"âŒ æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {model_path}")
        st.info("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶ä¸åº”ç”¨åœ¨åŒä¸€ç›®å½•ä¸‹")
        return None, None, device

    with st.spinner("ğŸ”„ æ­£åœ¨åŠ è½½é¢„è®­ç»ƒæ¨¡å‹..."):
        try:
            checkpoint = torch.load(model_path, map_location=device, weights_only=False)
        except TypeError:
            checkpoint = torch.load(model_path, map_location=device)

        model = MutualLearningModel(input_dim=480, num_classes=2).to(device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        scaler = checkpoint['scaler']
        return model, scaler, device


# ==========================================
# åº”ç”¨ä¸»å‡½æ•°
# ==========================================
def main():
    st.set_page_config(
        page_title="çŒªè‚ é“ç—…æ¯’è¯†åˆ«ç³»ç»Ÿ",
        page_icon="ğŸ·",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    st.title("ğŸ· çŒªè‚ é“ç—…æ¯’è¯†åˆ«ç³»ç»Ÿ")
    st.markdown("""
    <div style="background-color: #f0f2f6; padding: 15px; border-radius: 10px; margin-bottom: 20px;">
    <h3>ğŸ”¬ ç³»ç»Ÿè¯´æ˜</h3>
    <p>æœ¬ç³»ç»Ÿä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹å¯¹è›‹ç™½è´¨åºåˆ—è¿›è¡Œåˆ†ç±»ï¼Œåˆ¤æ–­å…¶æ˜¯å¦ä¸ºçŒªè‚ é“ç—…æ¯’ã€‚</p>
    <ul>
    <li><b>ç±»åˆ«0</b>: çŒªè‚ é“ç—…æ¯’</li>
    <li><b>ç±»åˆ«1</b>: éçŒªè‚ é“ç—…æ¯’</li>
    </ul>
    <p>æ¨¡å‹åŸºäºESM-2 35Mç‰¹å¾æå–å™¨å’Œå¤šåˆ†æ”¯èåˆæ¶æ„ï¼Œæä¾›é«˜ç²¾åº¦çš„é¢„æµ‹ç»“æœã€‚</p>
    </div>
    """, unsafe_allow_html=True)

    with st.sidebar:
        st.header("âš™ï¸ ç³»ç»Ÿè®¾ç½®")
        st.info("æ·±åº¦å­¦ä¹ èåˆæ¨¡å‹\n(ESM-2 + CNN + Transformer + Mamba)")
        st.markdown("### ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        1. **å•åºåˆ—é¢„æµ‹**: åœ¨è¾“å…¥æ¡†ä¸­ç²˜è´´è›‹ç™½è´¨åºåˆ—
        2. **æ‰¹é‡é¢„æµ‹**: ä¸Šä¼ åŒ…å«åºåˆ—çš„CSVæ–‡ä»¶
        3. æŸ¥çœ‹é¢„æµ‹ç»“æœåŠç½®ä¿¡åº¦
        """)
        st.markdown("### æ³¨æ„äº‹é¡¹")
        st.warning("""
        - ä»…æ”¯æŒæ ‡å‡†æ°¨åŸºé…¸å­—ç¬¦ (ACDEFGHIKLMNPQRSTVWY)
        - åºåˆ—é•¿åº¦å»ºè®®åœ¨10-5000ä¸ªæ°¨åŸºé…¸ä¹‹é—´
        - å½“å‰è¿è¡Œåœ¨ CPU æ¨¡å¼ï¼Œå¤„ç†é€Ÿåº¦è¾ƒæ…¢
        """)

    model, scaler, _ = load_model_and_scaler()
    feature_extractor = get_feature_extractor()

    if model is None or feature_extractor is None:
        st.stop()

    def predict_sequences(sequences: List[str]) -> List[dict]:
        if not sequences:
            return []

        with st.spinner(f"ğŸ§¬ æ­£åœ¨æå– {len(sequences)} æ¡åºåˆ—çš„ç‰¹å¾..."):
            features = feature_extractor.extract_features(sequences)

        features_scaled = scaler.transform(features)
        features_tensor = torch.FloatTensor(features_scaled).to(device)

        results = []
        with torch.no_grad():
            _, _, _, o_fused = model(features_tensor)
            probs = F.softmax(o_fused, dim=1)
            preds = torch.argmax(probs, dim=1).cpu().numpy()
            confidences = probs[:, 1].cpu().numpy()  # éçŒªè‚ é“ç—…æ¯’æ¦‚ç‡

        for i, (seq, pred, conf) in enumerate(zip(sequences, preds, confidences)):
            result = {
                'sequence_id': f"seq_{i + 1}",
                'sequence': seq[:50] + "..." if len(seq) > 50 else seq,
                'full_sequence': seq,
                'prediction': int(pred),
                'confidence': float(conf),
                'class_name': "éçŒªè‚ é“ç—…æ¯’" if pred == 1 else "çŒªè‚ é“ç—…æ¯’"
            }
            results.append(result)
        return results

    input_option = st.radio("é€‰æ‹©è¾“å…¥æ–¹å¼", ["å•åºåˆ—é¢„æµ‹", "æ‰¹é‡CSVé¢„æµ‹"], horizontal=True)

    if input_option == "å•åºåˆ—é¢„æµ‹":
        st.subheader("ğŸ”¤ è¾“å…¥è›‹ç™½è´¨åºåˆ—")
        sequence_input = st.text_area(
            "ç²˜è´´è›‹ç™½è´¨åºåˆ— (ä»…æ”¯æŒæ ‡å‡†æ°¨åŸºé…¸å­—ç¬¦)",
            height=150,
            placeholder="ä¾‹å¦‚: MAFSAEDVLKEYDRRRRMEALLLSLYYPNDRKLLDYKEWSPPRVQVECPKAPVEWNNPPSEKGLIVGHFSGIKYKGEKAQASEVDVNKMCCWVSKFKDAMRRYQGIQTCKIPGKVLSDLDMKHLKKADLIICAPNSYKKDDKPNQIKLLAVPTVMTKDDKQLLQEINELQDVVQDLRSLVEKNQIPAVDRAVTLTQRGELQAAGDKTLQEAVDRLQDKLQSLAEEGVKALQEELRKQLEAVDRAVTKLEQKLQDQVEALQARVDSLQAELRALQAQLAELQAELQALRSQLDELQAQLAELQAQLQALQSELQAQLSQLDELQAQLAELQAQLQALQSELQAQLSQLDELQAQLAELQAQLQALQSELQAQLSQLDELQAQLAELQAQLQ"
        )

        if st.button("ğŸ” å¼€å§‹é¢„æµ‹", type="primary"):
            if not sequence_input.strip():
                st.warning("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆçš„è›‹ç™½è´¨åºåˆ—")
            else:
                sequence = ''.join(filter(str.isalpha, sequence_input.strip().upper()))
                sequence = ''.join([aa for aa in sequence if aa in 'ACDEFGHIKLMNPQRSTVWY'])
                if len(sequence) < 10:
                    st.error("âŒ åºåˆ—é•¿åº¦è¿‡çŸ­ï¼Œè¯·è¾“å…¥è‡³å°‘10ä¸ªæ°¨åŸºé…¸çš„åºåˆ—")
                elif len(sequence) > 5000:
                    st.error("âŒ åºåˆ—é•¿åº¦è¿‡é•¿ï¼Œæœ€å¤§æ”¯æŒ5000ä¸ªæ°¨åŸºé…¸")
                else:
                    results = predict_sequences([sequence])
                    result = results[0]

                    color = "#ff4b4b" if result['prediction'] == 0 else "#1f77b4"
                    emoji = "ğŸ·" if result['prediction'] == 0 else "ğŸ¦ "

                    st.markdown(f"""
                    <div style="background-color: {color}15; border-left: 4px solid {color}; padding: 15px; border-radius: 0 8px 8px 0; margin: 15px 0;">
                    <h3 style="color: {color};">{emoji} é¢„æµ‹ç»“æœ: {result['class_name']}</h3>
                    <p><b>ç½®ä¿¡åº¦:</b> {result['confidence']:.2%}</p>
                    <p><b>åºåˆ—é¢„è§ˆ:</b> {result['sequence']}</p>
                    </div>
                    """, unsafe_allow_html=True)

                    st.subheader("ğŸ“ˆ ç½®ä¿¡åº¦åˆ†æ")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("çŒªè‚ é“ç—…æ¯’æ¦‚ç‡", f"{1 - result['confidence']:.2%}")
                    with col2:
                        st.metric("éçŒªè‚ é“ç—…æ¯’æ¦‚ç‡", f"{result['confidence']:.2%}")

                    import matplotlib.pyplot as plt
                    fig, ax = plt.subplots(figsize=(8, 2))
                    classes = ['PEV', 'non-PEV']
                    probabilities = [1 - result['confidence'], result['confidence']]
                    colors = ['#ff4b4b', '#1f77b4']
                    bars = ax.barh(classes, probabilities, color=colors)
                    ax.set_xlim(0, 1)
                    ax.set_title('Forecast probability distribution')
                    ax.bar_label(bars, fmt='%.2f', padding=3)
                    st.pyplot(fig)

                    with st.expander("ğŸ“‹ æŸ¥çœ‹å®Œæ•´åºåˆ—"):
                        st.code(result['full_sequence'])

    else:
        st.subheader("ğŸ“ ä¸Šä¼ CSVæ–‡ä»¶")
        st.markdown("""
        è¯·ä¸Šä¼ åŒ…å«è›‹ç™½è´¨åºåˆ—çš„CSVæ–‡ä»¶ï¼Œæ–‡ä»¶éœ€åŒ…å«`Sequence`åˆ—ã€‚
        **ç¤ºä¾‹æ ¼å¼:**
        ```
        ID,Sequence
        seq1,MAFSAEDVLKEYDRRRRMEALLLSLYYPNDRKLLDYKEWSPPRVQVECPKAPVEWNNPPSEKGLIVGHF
        seq2,MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLTYGV
        ```
        """)
        uploaded_file = st.file_uploader("é€‰æ‹©CSVæ–‡ä»¶", type=["csv"])

        if uploaded_file is not None:
            try:
                df = pd.read_csv(uploaded_file)
                if 'Sequence' not in df.columns:
                    st.error("âŒ CSVæ–‡ä»¶ä¸­ç¼ºå°‘'Sequence'åˆ—")
                else:
                    st.success(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡åºåˆ—")

                    with st.expander("ğŸ” æ•°æ®é¢„è§ˆ"):
                        st.dataframe(df.head())

                    sequences = []
                    valid_indices = []
                    for idx, row in df.iterrows():
                        seq = str(row['Sequence']).strip().upper()
                        seq_clean = ''.join([aa for aa in seq if aa in 'ACDEFGHIKLMNPQRSTVWY'])
                        if 10 <= len(seq_clean) <= 5000:
                            sequences.append(seq_clean)
                            valid_indices.append(idx)

                    st.info(f"â„¹ï¸ æœ‰æ•ˆåºåˆ—: {len(sequences)}/{len(df)}")

                    if st.button("ğŸš€ å¼€å§‹æ‰¹é‡é¢„æµ‹", type="primary"):
                        if not sequences:
                            st.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„åºåˆ—å¯ä»¥é¢„æµ‹")
                        else:
                            with st.spinner(f"ğŸ§  æ­£åœ¨é¢„æµ‹ {len(sequences)} æ¡åºåˆ—..."):
                                start_time = time.time()
                                results = predict_sequences(sequences)
                                elapsed_time = time.time() - start_time

                            results_df = pd.DataFrame(results)
                            result_indices = pd.Series(valid_indices, name='original_index')
                            results_with_index = pd.concat([result_indices, results_df], axis=1)

                            output_df = df.copy()
                            output_df['Prediction'] = "æ— æ•ˆåºåˆ—"
                            output_df['Class'] = "æ— æ•ˆåºåˆ—"
                            output_df['Confidence'] = 0.0
                            for _, row in results_with_index.iterrows():
                                idx = int(row['original_index'])
                                output_df.at[idx, 'Prediction'] = row['prediction']
                                output_df.at[idx, 'Class'] = row['class_name']
                                output_df.at[idx, 'Confidence'] = row['confidence']

                            st.subheader("ğŸ“Š é¢„æµ‹ç»Ÿè®¡")
                            col1, col2, col3 = st.columns(3)
                            total_valid = len(sequences)
                            pig_virus_count = sum(1 for r in results if r['prediction'] == 0)
                            with col1:
                                st.metric("æœ‰æ•ˆåºåˆ—æ•°", total_valid)
                            with col2:
                                st.metric("çŒªè‚ é“ç—…æ¯’", pig_virus_count)
                            with col3:
                                st.metric("éçŒªè‚ é“ç—…æ¯’", total_valid - pig_virus_count)

                            st.success(f"âœ… é¢„æµ‹å®Œæˆ! è€—æ—¶: {elapsed_time:.2f} ç§’")
                            st.subheader("ğŸ” ç»“æœé¢„è§ˆ")
                            st.dataframe(output_df.head(10))

                            csv = output_df.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                label="ğŸ“¥ ä¸‹è½½å®Œæ•´ç»“æœ (CSV)",
                                data=csv,
                                file_name="prediction_results.csv",
                                mime="text/csv",
                                type="primary"
                            )

                            import matplotlib.pyplot as plt
                            fig, ax = plt.subplots(figsize=(10, 6))
                            class_counts = output_df[output_df['Prediction'] != "æ— æ•ˆåºåˆ—"]['Class'].value_counts()
                            colors = ['#ff4b4b', '#1f77b4']
                            bars = class_counts.plot(kind='bar', color=colors, ax=ax)
                            ax.set_title('é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ', fontsize=16)
                            ax.set_xlabel('ç±»åˆ«', fontsize=12)
                            ax.set_ylabel('æ•°é‡', fontsize=12)
                            ax.tick_params(axis='x', rotation=0)
                            for i, v in enumerate(class_counts.values):
                                ax.text(i, v + 0.5, str(v), ha='center', fontweight='bold')
                            st.pyplot(fig)

            except Exception as e:
                st.error(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")


if __name__ == "__main__":
    main()
